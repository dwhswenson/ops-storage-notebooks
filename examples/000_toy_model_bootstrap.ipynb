{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: missing monkey patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining the first trajectories for a Toy Model\n",
    "\n",
    "Tasks covered in this notebook:\n",
    "\n",
    "* Setting up a system using the `ToyDynamics` package\n",
    "* Using a user-defined function to create a collective variable\n",
    "* Using collective variables to define states and interfaces\n",
    "* Storing things manually\n",
    "\n",
    "## Getting an initial path\n",
    "\n",
    "Path sampling methods require that the user supply an input path for each path ensemble. This means that you must somehow generate a first input path. In general, getting the first input paths for TIS boils down to solving two problems:\n",
    "\n",
    "1. Getting a trajectory that samples the rare event.\n",
    "2. Filling all the path ensembles with acceptable trajectories.\n",
    "\n",
    "Since transition paths satisfy all the path ensembles between two states, a common approach is to use the same initial path for all path ensembles (reversing it where necessary). This way, once you've solved problem 1, problem 2 is trivial.\n",
    "\n",
    "The first rare path can come from any number of sources. The obvious approach might be to find a transition path from a committor analysis, because this would give you a path that satisfies the true dynamics. However, the initial path doesn't *need* to satisfy the true dynamics of the system (later we can equilibrate the path ensemble anyway). This means that other approaches, such as high-temperature trajectories, can be used for the first path. One of the most widely-used methods to get an initial trajectory is to generate a transition trajectory using metadynamics. However, the downside of using paths that don't satisfy the true dynamics is that it might be harder to get them to equilibrate to the correct path ensemble. It seems that this has been more of a problem with paths from high temperature runs than with paths from metadynamics: in the first metadynamics transition, the barrier region is often quite similar to the native dynamics.\n",
    "\n",
    "In this example, we use a bootstrapping approach, which does create paths satisfying the true dynamics of the system. This bootstrapping is nice because it is quick and convenient, although it works best on smaller systems with less complicated transitions. It works by running normal MD to generate a path that satisfies the innermost interface, and then performing shooting moves in that interface's path ensemble until we have a path that crosses the next interface. Then we switch to the path ensemble for the next interface, and shoot until the path crossing the interface after that. The process continues until we have paths for all interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "%matplotlib inline\n",
    "import openpathsampling as paths\n",
    "import numpy as np\n",
    "\n",
    "# used for visualization of the 2D toy system\n",
    "# we use the %run magic because this isn't in a package\n",
    "#%run ../resources/toy_plot_helpers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic system setup\n",
    "\n",
    "First we set up our system: for the toy dynamics, this involves defining a potential energy surface (PES), setting up an integrator, and giving the simulation an initial configuration. In real MD systems, the PES is handled by the combination of a topology file and a force field definition, and the initial configuration would come from a file instead of being described by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience for the toy dynamics\n",
    "import openpathsampling.engines.toy as toys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the toy system\n",
    "\n",
    "First we need to describe the system we'll be simulating. With biomolecular systems, this is often done with an initial PDB structure and a choice of force field. For the toy model, we need to give a snapshot as a template, as well as a potential energy surface. The template snapshot also includes a pointer to the topology information (which is relatively simple for the toy systems.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy_PES supports adding/subtracting various PESs. \n",
    "# The OuterWalls PES type gives an x^6+y^6 boundary to the system.\n",
    "pes = (\n",
    "    toys.OuterWalls([1.0, 1.0], [0.0, 0.0]) +\n",
    "    toys.Gaussian(-0.7, [12.0, 12.0], [0.0, 0.4]) +\n",
    "    toys.Gaussian(-0.7, [12.0, 12.0], [-0.5, -0.5]) +\n",
    "    toys.Gaussian(-0.7, [12.0, 12.0], [0.5, -0.5])\n",
    ")\n",
    "\n",
    "topology=toys.Topology(\n",
    "    n_spatial = 2,\n",
    "    masses =[1.0, 1.0],\n",
    "    pes = pes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the engine\n",
    "\n",
    "The engine needs the template snapshot we set up above, as well as an integrator and a few other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "integ = toys.LangevinBAOABIntegrator(dt=0.02, temperature=0.1, gamma=2.5)\n",
    "\n",
    "options={\n",
    "    'integ' : integ,\n",
    "    'n_frames_max' : 5000,\n",
    "    'n_steps_per_frame' : 1\n",
    "}\n",
    "\n",
    "toy_eng = toys.Engine(\n",
    "    options=options,\n",
    "    topology=topology\n",
    ")\n",
    "toy_eng.initialized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = toys.Snapshot(\n",
    "    coordinates=np.array([[-0.5, -0.5]]), \n",
    "    velocities=np.array([[0.0,0.0]]),\n",
    "    engine=toy_eng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_eng.current_snapshot = template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we make this engine into the default engine for any `PathMover` that requires an one (e.g., shooting movers, minus movers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.PathMover.engine = toy_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the potential energy surface we've created:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining states and interfaces\n",
    "\n",
    "TIS methods usually require that you define states and interfaces before starting the simulation. State and interfaces are both defined in terms of `Volume` objects. The most common type of `Volume` is one based on some set of collective variables, so the first thing we have to do is to define the collective variable.\n",
    "\n",
    "For this system, we'll define the collective variables as circles centered on the middle of the state. OPS allows us to define one function for the circle, which is parameterized by different centers. Note that each collective variable is in fact a separate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle(snapshot, center):\n",
    "    import math\n",
    "    return math.sqrt((snapshot.xyz[0][0]-center[0])**2 + (snapshot.xyz[0][1]-center[1])**2)\n",
    "    \n",
    "opA = paths.CoordinateFunctionCV(name=\"opA\", f=circle, center=[-0.5, -0.5])\n",
    "opB = paths.CoordinateFunctionCV(name=\"opB\", f=circle, center=[0.5, -0.5])\n",
    "opC = paths.CoordinateFunctionCV(name=\"opC\", f=circle, center=[0.0, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the states and interfaces in terms of these order parameters. The `CVRangeVolumeSet` gives a shortcut to create several volume objects using the same collective variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateA = paths.CVDefinedVolume(opA, 0.0, 0.2)\n",
    "stateB = paths.CVDefinedVolume(opB, 0.0, 0.2)\n",
    "stateC = paths.CVDefinedVolume(opC, 0.0, 0.2)\n",
    "\n",
    "interfacesA = paths.VolumeInterfaceSet(opA, 0.0, [0.2, 0.3, 0.4])\n",
    "interfacesB = paths.VolumeInterfaceSet(opB, 0.0, [0.2, 0.3, 0.4])\n",
    "interfacesC = paths.VolumeInterfaceSet(opC, 0.0, [0.2, 0.3, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the MSTIS transition network\n",
    "\n",
    "Once we have the collective variables, states, and interfaces defined, we can create the entire transition network. In this one small piece of code, we create all the path ensembles needed for the simulation, organized into structures to assist with later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_outers = paths.MSOuterTISInterface.from_lambdas(\n",
    "    {ifaces: 0.5\n",
    "     for ifaces in [interfacesA, interfacesB, interfacesC]}\n",
    ")\n",
    "mstis = paths.MSTISNetwork(\n",
    "    [(stateA, interfacesA),\n",
    "     (stateB, interfacesB),\n",
    "     (stateC, interfacesC)],\n",
    "    ms_outers=ms_outers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap to fill all interfaces\n",
    "\n",
    "Now we actually run the bootstrapping calculation. The `full_bootstrap` function requires an initial snapshot in the state, and then it will generate trajectories satisfying TIS ensemble for the given interfaces. To fill all the ensembles in the MSTIS network, we need to do this once for each initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! Completed Bootstrapping cycle step 152 in ensemble 4/4.\n"
     ]
    }
   ],
   "source": [
    "initA = toys.Snapshot(\n",
    "    coordinates=np.array([[-0.5, -0.5]]), \n",
    "    velocities=np.array([[1.0,0.0]]),\n",
    ")\n",
    "bootstrapA = paths.FullBootstrapping(\n",
    "    transition=mstis.from_state[stateA],\n",
    "    snapshot=initA,\n",
    "    engine=toy_eng,\n",
    "    forbidden_states=[stateB, stateC],\n",
    "    extra_interfaces=[ms_outers.volume_for_interface_set(interfacesA)]\n",
    ")\n",
    "gsA = bootstrapA.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! Completed Bootstrapping cycle step 125 in ensemble 3/3.\n"
     ]
    }
   ],
   "source": [
    "initB = toys.Snapshot(\n",
    "    coordinates=np.array([[0.5, -0.5]]), \n",
    "    velocities=np.array([[-1.0,0.0]]),\n",
    ")\n",
    "\n",
    "bootstrapB = paths.FullBootstrapping(\n",
    "    transition=mstis.from_state[stateB], \n",
    "    snapshot=initB, \n",
    "    engine=toy_eng,\n",
    "    forbidden_states=[stateA, stateC]\n",
    ")\n",
    "gsB = bootstrapB.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! Completed Bootstrapping cycle step 81 in ensemble 3/3.\n"
     ]
    }
   ],
   "source": [
    "initC = toys.Snapshot(\n",
    "    coordinates=np.array([[0.0, 0.4]]), \n",
    "    velocities=np.array([[0.0,-0.5]]),\n",
    ")\n",
    "bootstrapC = paths.FullBootstrapping(\n",
    "    transition=mstis.from_state[stateC], \n",
    "    snapshot=initC, \n",
    "    engine=toy_eng, \n",
    "    forbidden_states=[stateA, stateB]\n",
    ")\n",
    "gsC = bootstrapC.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done that for all 3 states, let's look at the trajectories we generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we join these into one `SampleSet`. The function `relabel_replicas_per_ensemble` ensures that the trajectory associated with each ensemble has a unique replica ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sample_set = paths.SampleSet.relabel_replicas_per_ensemble(\n",
    "    [gsA, gsB, gsC]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing stuff\n",
    "\n",
    "Up to this point, we haven't stored anything in files. In other notebooks, a lot of the storage is done automatically. Here we'll show you how to store a few things manually. Instead of storing the entire bootstrapping history, we'll only store the final trajectories we get out.\n",
    "\n",
    "First we create a file. When we create it, the file also requires the `template` snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "root.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-21 17:35:01,458 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table uuid\n",
      "2020-01-21 17:35:01,459 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table tables\n",
      "2020-01-21 17:35:01,471 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table samples\n",
      "2020-01-21 17:35:01,488 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table sample_sets\n",
      "2020-01-21 17:35:01,495 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table trajectories\n",
      "2020-01-21 17:35:01,506 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table move_changes\n",
      "2020-01-21 17:35:01,522 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table steps\n",
      "2020-01-21 17:35:01,535 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table details\n",
      "2020-01-21 17:35:01,548 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table simulation_objects\n"
     ]
    }
   ],
   "source": [
    "from openpathsampling.experimental.storage.sql_backend import SQLStorageBackend\n",
    "from openpathsampling.experimental.storage.ops_storage import OPSStorage, OPSClassInfoContainer, ops_class_info, ops_schema\n",
    "\n",
    "backend = SQLStorageBackend(\"test.sql\", mode='w')\n",
    "storage = OPSStorage.from_backend(\n",
    "    backend=backend,\n",
    "    schema=ops_schema,\n",
    "    class_info=ops_class_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The storage will recursively store data, so storing `total_sample_set` leads to automatic storage of all the `Sample` objects in that sampleset, which in turn leads to storage of all the ensemble, trajectories, and snapshots.\n",
    "\n",
    "Since the path movers used in bootstrapping and the engine are not required for the sampleset, they would not be stored. We explicitly store the engine for later use, but we won't need the path movers, so we don't try to store them.\n",
    "\n",
    "The `sync_all()` function ensures that all the data that has been created is also saved to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "2020-01-21 17:35:01,593 - openpathsampling.experimental.storage.storage - DEBUG - Starting save\n",
      "2020-01-21 17:35:01,599 - openpathsampling.experimental.storage.sql_backend - DEBUG - Looking for 1 UUIDs\n",
      "2020-01-21 17:35:01,602 - openpathsampling.experimental.storage.sql_backend - DEBUG - New block of 1 UUIDs\n",
      "2020-01-21 17:35:01,605 - openpathsampling.experimental.storage.sql_backend - DEBUG - Found 0 UUIDs\n",
      "2020-01-21 17:35:01,606 - openpathsampling.experimental.storage.storage - DEBUG - Listing all objects to save\n",
      "2020-01-21 17:35:01,642 - openpathsampling.experimental.storage.storage - DEBUG - Checking if objects already exist in database\n",
      "2020-01-21 17:35:01,644 - openpathsampling.experimental.storage.sql_backend - DEBUG - Looking for 517 UUIDs\n",
      "2020-01-21 17:35:01,646 - openpathsampling.experimental.storage.sql_backend - DEBUG - New block of 517 UUIDs\n",
      "2020-01-21 17:35:01,676 - openpathsampling.experimental.storage.sql_backend - DEBUG - Found 0 UUIDs\n",
      "2020-01-21 17:35:01,698 - openpathsampling.experimental.storage.storage - INFO - Registering tables for 327 missing objects\n",
      "2020-01-21 17:35:01,704 - openpathsampling.experimental.storage.sql_backend - INFO - Add schema table snapshot0\n",
      "2020-01-21 17:35:01,752 - openpathsampling.experimental.storage.storage - INFO - Registered 1 new tables: ['snapshot0']\n",
      "2020-01-21 17:35:01,753 - openpathsampling.experimental.storage.storage - DEBUG - Filling 5 tables: ['sample_sets', 'samples', 'trajectories', 'simulation_objects', 'snapshot0']\n",
      "2020-01-21 17:35:01,755 - openpathsampling.experimental.storage.storage - DEBUG - Storing 1 objects to table sample_sets\n",
      "2020-01-21 17:35:01,769 - openpathsampling.experimental.storage.storage - DEBUG - Storing complete\n",
      "2020-01-21 17:35:01,771 - openpathsampling.experimental.storage.storage - DEBUG - Storing 10 objects to table samples\n",
      "2020-01-21 17:35:01,781 - openpathsampling.experimental.storage.storage - DEBUG - Storing complete\n",
      "2020-01-21 17:35:01,782 - openpathsampling.experimental.storage.storage - DEBUG - Storing 7 objects to table trajectories\n",
      "2020-01-21 17:35:01,804 - openpathsampling.experimental.storage.storage - DEBUG - Storing complete\n",
      "2020-01-21 17:35:01,807 - openpathsampling.experimental.storage.storage - DEBUG - Storing 172 objects to table simulation_objects\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type type is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-915d2c01164c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pdb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_sample_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoy_eng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/pysrc/openpathsampling/openpathsampling/experimental/storage/storage.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj_list)\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;31m# serialize(o)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mstorables_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorables_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# special handling for simulation objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/pysrc/openpathsampling/openpathsampling/experimental/storage/storage.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;31m# serialize(o)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mstorables_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorables_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# special handling for simulation objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/pysrc/openpathsampling/openpathsampling/experimental/storage/custom_json.py\u001b[0m in \u001b[0;36msimobj_serializer\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimobj_serializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sim_serializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/pysrc/openpathsampling/openpathsampling/experimental/storage/serialization.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         return {'uuid': serialization.get_uuid(obj),\n\u001b[0;32m--> 103\u001b[0;31m                 'json': self.json_encoder(obj)}\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/Dropbox/pysrc/openpathsampling/openpathsampling/experimental/storage/custom_json.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mCustomJSONDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type type is not JSON serializable"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/dwhs/miniconda3/envs/dev/lib/python3.7/json/encoder.py\u001b[0m(179)\u001b[0;36mdefault\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    177 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    178 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m--> 179 \u001b[0;31m        raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "\u001b[0m\u001b[0;32m    180 \u001b[0;31m                        f'is not JSON serializable')\n",
      "\u001b[0m\u001b[0;32m    181 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "%pdb 1\n",
    "storage.save(total_sample_set)\n",
    "storage.save(toy_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check to make sure that we actually have stored the objects that we claimed to store. There should be 0 pathmovers, 1 engine, 12 samples (4 samples from each of 3 transitions), and 1 sampleset. There will be some larger number of snapshots. There will also be a larger number of ensembles, because each ensemble is defined in terms of subensembles, each of which gets saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we close the storage. Not strictly necessary, but a good habit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
